{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8YVA_634OFk"
      },
      "source": [
        "\n",
        "The problem we will solve is to convert from Celsius to Fahrenheit, where the approximate formula is:\n",
        "\n",
        "$$ f = c \\times 1.8 + 32 $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA93WUy1zzWf"
      },
      "source": [
        "## Import dependencies\n",
        "\n",
        "First, import TensorFlow. Here, we're calling it `tf` for ease of use. We also tell it to only display errors.\n",
        "\n",
        "Next, import [NumPy](http://www.numpy.org/) as `np`. Numpy helps us to represent our data as highly performant lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZMgCvSRFqxE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_WQEM5MGmg3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#import logging\n",
        "#logger = tf.get_logger()\n",
        "#logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3EQFi20buB"
      },
      "source": [
        "## Set up training data\n",
        "\n",
        "As we saw before, supervised Machine Learning is all about figuring out an algorithm given a set of inputs and outputs. Since the task in this Codelab is to create a model that can give the temperature in Fahrenheit when given the degrees in Celsius, we create two lists `celsius_q` and `fahrenheit_a` that we can use to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg4pn6aI1vms"
      },
      "outputs": [],
      "source": [
        "X = np.array([-40, -10,  0,  8, 15, 22,  38,100],  dtype=float)\n",
        "Y = np.array([-40,  14, 32, 46, 59, 72, 100,180],  dtype=float)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwJGmDrQ0EoB"
      },
      "source": [
        "### Some Machine Learning terminology\n",
        "\n",
        " - **Feature** — The input(s) to our model. In this case, a single value — the degrees in Celsius.\n",
        "\n",
        " - **Labels** — The output our model predicts. In this case, a single value — the degrees in Fahrenheit.\n",
        "\n",
        " - **Example** — A pair of inputs/outputs used during training. In our case a pair of values from `celsius_q` and `fahrenheit_a` at a specific index, such as `(22,72)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRllo2HLfXiu"
      },
      "outputs": [],
      "source": [
        "l0 = tf.keras.layers.Dense(units=1, input_shape=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F00_J9duLBD"
      },
      "source": [
        "### Assemble layers into the model\n",
        "\n",
        "\n",
        "\n",
        "This model has just a single layer, l0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSp-GpLSuMRq"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([l0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7pfHfWxust0"
      },
      "source": [
        "**Note**\n",
        "\n",
        "You will often see the layers defined inside the model definition, rather than beforehand:\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiZG7uhm8qCF"
      },
      "source": [
        "## Compile the model, with loss and optimizer functions\n",
        "\n",
        "Before training, the model has to be compiled. When compiled for training, the model is given:\n",
        "\n",
        "- **Loss function** — A way of measuring how far off predictions are from the desired outcome. (The measured difference is called the \"loss\".)\n",
        "\n",
        "- **Optimizer function** — A way of adjusting internal values in order to reduce the loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8YQN1H41L-Y"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mean_absolute_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Jk4dG91dvD"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Train the model by calling the `fit` method.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpRrl7WK10Pq",
        "outputId": "54150571-f9df-496a-eb8e-932e5452effe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 35.4781\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 35.4780\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 35.4781\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.4781\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 35.4780\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4780\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 35.4781\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.4781\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 35.4781\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 35.4781\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 35.4781\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 35.4781\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 35.4781\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 35.4781\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 35.4781\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 35.4781\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4780\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 35.4781\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 35.4781\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 35.4781\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 35.4781\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4780\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4782\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4782\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4782\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4780\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 35.4781\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4782\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4782\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 35.4781\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 35.4781\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 35.4781\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4780\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4780\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 35.4781\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 35.4781\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4782\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 35.4781\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 35.4781\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.4781\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.4781\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 35.4781\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.4781\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.4781\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.4781\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 35.4781\n",
            "Finished training the model\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(X, Y, epochs=500)\n",
        "print(\"Finished training the model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "IeK6BzfbdO6_",
        "outputId": "aab5b96c-0c7b-4c70-c583-d4f0956a0291"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f048ab08de09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch Number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss Magnitude\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel(\"Loss Magnitude\")\n",
        "plt.plot(history.history['loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtQGDMob5LOD"
      },
      "source": [
        "## Use the model to predict values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNzL4lS2Gui",
        "outputId": "5c2aab60-9a14-409e-c788-8752fd2ef4b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[211.38812]]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict([100.0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRrOky5gm20Z"
      },
      "source": [
        "## Looking at the layer weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmIkVdkbnZJI",
        "outputId": "e069e2ff-908d-4121-8c74-e4a1e9ee4523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are the layer variables: [array([[1.7946091]], dtype=float32), array([31.92721], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(\"These are the layer variables: {}\".format(l0.get_weights()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "y=1.7*x+32"
      ],
      "metadata": {
        "id": "9D74IN66d83d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2zTA-rDS5Xk",
        "outputId": "f2b8b9e0-ed71-4a55-8d19-29b69cef73be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training the model\n",
            "[[188.92618]]\n",
            "Model predicts that 100 degrees Celsius is: [[188.92618]] degrees Fahrenheit\n",
            "These are the l0 variables: [array([[ 0.07035083,  0.8506314 ,  0.3351732 , -0.69770515]],\n",
            "      dtype=float32), array([ 3.2409453 ,  3.2578416 , -0.92679924, -3.203476  ], dtype=float32)]\n",
            "These are the l1 variables: [array([[ 1.0536134 ,  0.10696054, -0.07302587,  0.55075794],\n",
            "       [ 0.00843681,  0.19074577, -0.7580406 , -0.52171355],\n",
            "       [ 0.11617909, -0.65199894,  0.14700097,  0.41756064],\n",
            "       [-0.04044716, -0.1402017 ,  0.5505923 ,  0.77880055]],\n",
            "      dtype=float32), array([ 3.0257201,  1.8977722, -3.135932 ,  0.3224608], dtype=float32)]\n",
            "These are the l2 variables: [array([[-0.71436554,  0.11941686,  0.12463976, -0.6626998 , -0.7721245 ,\n",
            "         0.27365842, -0.27038193, -0.6450142 ],\n",
            "       [-0.19234203, -0.31493765,  0.07077456,  0.24781434, -0.5647733 ,\n",
            "         0.00700926, -0.3462929 ,  0.46602234],\n",
            "       [ 0.6262089 , -0.13587615, -0.6963743 ,  0.6133925 ,  0.78681946,\n",
            "        -0.38654375,  0.25373527, -0.03867978],\n",
            "       [-0.6474816 ,  0.01507053,  0.43886635,  0.38667095,  0.17689376,\n",
            "         0.35215774, -0.2532616 , -0.17664136]], dtype=float32), array([-3.3998349,  1.2735585,  1.8758506, -3.328939 , -3.1032758,\n",
            "        2.7357183, -1.9113394, -2.422115 ], dtype=float32)]\n",
            "These are the l3 variables: [array([[-0.34005025],\n",
            "       [-0.00722763],\n",
            "       [ 0.18255392],\n",
            "       [-0.42117056],\n",
            "       [-0.916099  ],\n",
            "       [ 0.21167415],\n",
            "       [-0.18427546],\n",
            "       [-0.03899048]], dtype=float32), array([2.9469295], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "l0 = tf.keras.layers.Dense(units=4, input_shape=[1])\n",
        "\n",
        "l1 = tf.keras.layers.Dense(units=4)\n",
        "l2 = tf.keras.layers.Dense(units=8)\n",
        "\n",
        "l3 = tf.keras.layers.Dense(units=1)\n",
        "\n",
        "model = tf.keras.Sequential([l0,l1, l2,l3])\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
        "model.fit(X, Y, epochs=500, verbose=False)\n",
        "print(\"Finished training the model\")\n",
        "print(model.predict([100.0]))\n",
        "print(\"Model predicts that 100 degrees Celsius is: {} degrees Fahrenheit\".format(model.predict([100.0])))\n",
        "print(\"These are the l0 variables: {}\".format(l0.get_weights()))\n",
        "print(\"These are the l1 variables: {}\".format(l1.get_weights()))\n",
        "print(\"These are the l2 variables: {}\".format(l2.get_weights()))\n",
        "print(\"These are the l3 variables: {}\".format(l3.get_weights()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrpFFlgYhCty"
      },
      "source": [
        "As you can see, this model is also able to predict the corresponding Fahrenheit value really well. But when you look at the variables (weights) in the `l0` and `l1` layers, they are nothing even close to ~1.8 and ~32. The added complexity hides the \"simple\" form of the conversion equation.\n",
        "\n",
        "Stay tuned for the upcoming video on how Dense layers work for the explanation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}